{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbUQxHG8YM78r4bXT7gjWH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rM9PcI2aWOGj"},"source":["#must use this numpy version due to eval compatability\n","!pip install numpy==1.17.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xgrRRRA8ohp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWLMa89J9Eq6"},"source":["#moving to the desired position on drive\n","%cd drive/MyDrive/tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bQzkGkE9MoG"},"source":["# downloading the object detection repo from github\n","import os\n","import pathlib\n","\n","!git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnIcX8-N9Onw"},"source":["# Install the Object Detection API\n","%cd models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-o8kqgar9Qd1"},"source":["#run model builder test\n","%cd ../..\n","!python models/research/object_detection/builders/model_builder_tf2_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JL-HXD-u9Sys"},"source":["#paths to the tfrecord files and pbtxt labelmap\n","train_record_path = 'bee_data_tfrecord/train.tfrecord'\n","test_record_path = 'bee_data_tfrecord/val.tfrecord'\n","labelmap_path = 'bee_data_tfrecord/labelmap.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESOIZJVK9UWD"},"source":["#parameters for training\n","batch_size = 16\n","num_steps = 10000\n","num_eval_steps = 100\n","\n","fine_tune_checkpoint = 'zoo_models/ssd_mobilenet_v1/checkpoint/ckpt-0'\n","\n","base_config_path = 'zoo_models/ssd_mobilenet_v1/pipeline.config'\n","\n","num_classes=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oojDvJ59Z-r"},"source":["# edit configuration file with parameters\n","\n","import re\n","\n","with open(base_config_path) as f:\n","    config = f.read()\n","\n","with open('model_config.config', 'w') as f:\n","  \n","  # Set labelmap path\n","  config = re.sub('label_map_path: \".*?\"', \n","             'label_map_path: \"{}\"'.format(labelmap_path), config)\n","  \n","  # Set fine_tune_checkpoint path\n","  config = re.sub('fine_tune_checkpoint: \".*?\"',\n","                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n","  \n","  # Set train tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n","                  'input_path: \"{}\"'.format(train_record_path), config)\n","  \n","  # Set test tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/eval)(.*?\")', \n","                  'input_path: \"{}\"'.format(test_record_path), config)\n","  \n","  # Set number of classes.\n","  config = re.sub('num_classes: [0-9]+',\n","                  'num_classes: {}'.format(num_classes), config)\n","  \n","  # Set batch size\n","  config = re.sub('batch_size: [0-9]+',\n","                  'batch_size: {}'.format(batch_size), config)\n","  \n","  # Set training steps\n","  config = re.sub('num_steps: [0-9]+',\n","                  'num_steps: {}'.format(num_steps), config)\n","  \n","  # Set fine-tune checkpoint type to detection\n","  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n","             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n","  \n","  f.write(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dd0awpvt9eYf"},"source":["#some \"PATH_TO_BE_CONFIGURED\" in the config file is not set here so have to be set manually...\n","#so make sure no \"PATH_TO_BE_CONFIGURED\" is left in the config file\n","%cat model_config.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5quTIF689gB_"},"source":["#Where to put the training data and path to the config file\n","model_dir = 'training_data/training_ssd_mobilenet_v1/'\n","pipeline_config_path = 'model_config.config'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TBBkQ2b2ygQ0"},"source":["#below the training script is executed, results will be put in the model_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbqfDdrQ9h1G"},"source":["!python models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_config_path} \\\n","    --model_dir={model_dir} \\\n","    --num_train_steps={num_steps} \\\n","    --checkpoint_every_n=400 \\\n","    --alsologtostderr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAm1K8Rn9jmq"},"source":["#launch tensorboard to view training\n","%load_ext tensorboard\n","%tensorboard --logdir 'training_data/training_ssd_mobilenet_v1/train'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8d2FvjS3Owuh"},"source":["#in some versions of the repo this have to be changed, if it does not run properly, skip\n","with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\n","    tf_utils = f.read()\n","\n","with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\n","  # Set labelmap path\n","  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\n","  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\n","  f.write(tf_utils)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mo36PFmkO6P4"},"source":["#export the model from training data to inference graph \n","output_directory = 'inference_graphs/inference_graph_ssd_mobilenet_v1'\n","\n","!python models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {model_dir} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_config_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nztf00D4O_IN"},"source":["#the rest of the code is for testing the model on example images\n","import io\n","import os\n","import scipy.misc\n","import numpy as np\n","import six\n","import time\n","import glob\n","from IPython.display import display\n","\n","from six import BytesIO\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzNh6vIBPAmN"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path (this can be local or on colossus)\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lU55YOOuPDgu"},"source":["category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6PTnqe3PFae"},"source":["tf.keras.backend.clear_session()\n","model = tf.saved_model.load('inference_graphs/inference_graph_ssd_mobilenet_v1/saved_model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCgBu9ULPIb-"},"source":["def run_inference_for_single_image(model, image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = model.signatures['serving_default']\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VANgKs6iPJN6"},"source":["for image_path in glob.glob('inference/*.jpeg'):\n","  image_np = load_image_into_numpy_array(image_path)\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      line_thickness=8,\n","      min_score_thresh=0.3)\n","  display(Image.fromarray(image_np))"],"execution_count":null,"outputs":[]}]}